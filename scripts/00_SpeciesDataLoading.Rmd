---
title: "00_SpeciesDataLoading"
author: "Madrone Environmental Services"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r}
#This bit of code turns off warning messages in your R markdown output.
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Standardize your libraries for use for the modelling process.

```{r}
knitr::opts_chunk$set(warning = FALSE)
list.of.packages <- c("tidyverse", "lubridate","chron","bcdata", "bcmaps","sf", "rgdal", "readxl", "Cairo", "OpenStreetMap", "ggmap","rgbif")
# Check you have them and load them
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
```

## Loading Data from GBIF

Use this script to load data from Global Biodiversity Information Framework (GBIF). Please note that it may take some time if there are a lot of points. Subsequent to loading, we convert the points to an object of class sf to spatially reference it:

```{r Western Skink Data Loading, echo=TRUE}
myspecies <- c("Plestiodon skiltonianus")

gbif_data <- occ_data(scientificName = myspecies, hasCoordinate = TRUE, limit = 20000, decimalLongitude = "-124, -114", decimalLatitude = "49, 50")

# take a look at the downloaded data:
gbif_data

myspecies_coords <- gbif_data$data[ , c("decimalLongitude", "decimalLatitude", "individualCount", "occurrenceStatus", "coordinateUncertaintyInMeters", "institutionCode", "references")]

myspecies_coords <- st_as_sf(myspecies_coords, coords = c("decimalLongitude", "decimalLatitude"), crs = st_crs(4326))

st_write(myspecies_coords,
         dsn = "R:/22.0253_SHM_Year2/Worked_Examples/Western_Skink",
         layer = "gbif.shp",
         driver = "ESRI Shapefile")

```

### Cleaning Data

There may be points that have abundance tallies of zero. This is a confusing metric, and these points may need to be excluded.The following cleaning scripts can capture those and identify absence points. These may be important for some modelling practices, so this process and other cleaning should be tailored to your dataset and needs.

```{r}
names(myspecies_coords)
sort(unique(myspecies_coords$individualCount))  # notice if some points correspond to zero abundance
sort(unique(myspecies_coords$occurrenceStatus))  # check for different indications of "absent", which could be in different languages! and remember that R is case-sensitive
```

## Additional Data

```{r Loading WSI and CDC Occurrences, echo=TRUE}
fgdb <- "C:/Users/rborthwi/OneDrive - MADRONE ENVIRONMENTAL SERVICES LTD/Documents/Data Analysis/22.0253/bc-cdc-species-habitat-modelling/data/ModelData.gdb/ModelData.gdb"

# List all feature classes in a file geodatabase
fc_list <- ogrListLayers(fgdb)
print(fc_list)
```

```{r Spatiallizing data, include=FALSE}
#Second, load the species data of interest - write function that automates this:
fc_PLSK_range <- sf::st_read(fgdb, layer = fc_list[[1]])
fc_PLSK_EO <- sf::st_read(fgdb, layer = fc_list[[3]])
fc_PLSK_EO_Ext <- sf::st_read(fgdb, layer = fc_list[[4]])
fc_PLSK_WSI_SO <- sf::st_read(fgdb, layer = fc_list[[5]])
fc_PLSK_iNat_obsc <- sf::st_read(fgdb, layer = fc_list[[6]])
```

## Plots

Testing the data and visualizing it:

```{r}
#Loading Natural Resource Districts for BC.
CO <- nr_districts() %>% filter(ORG_UNIT %in% c("DOS", "DRM", "DCS", "DSE"))
CO_latlon <- st_transform(CO, crs=4326)
st_bbox(CO_latlon)

#Plotting range boundaries from Provincial Staff - these may not always be available. 
ggplot() +
  geom_sf(data = fc_PLSK_range) +
  geom_sf(data = fc_PLSK_EO_Ext) +
  geom_sf(data = fc_PLSK_EO, color = "blue", size = 1) #+
  geom_sf(data = fc_PLSK_WSI_SO, color = "green") +
  geom_sf(data = myspecies_coords, color = "red") 



```

I do this first to do a quick eye-ball test of overlapping points from different data sets. Note that the CDC Element Occurences are polygons, and they overlap well with the species occurrence information. They don't appear to overlap with GBIF data. There are multiple options to move forward here. I carry out two options here. First, I take the easiest path and join the points and ignore the polygons. Removing them for the sake of simplicity and consistency. Second, intersect points from WSI_SO with EO polygons, then combine the GBIF and SO/EO data into one SF. Another approach may be to include a weighting for the EO polygons based on the number/density of SO within the polygon. However, this requires a deeper dive into the existing data to ensure that sampling bias does not impacting any weighting, and that is an involved process.

## Combine the Data

```{r}
names(fc_PLSK_EO)
names(fc_PLSK_WSI_SO)
names(myspecies_coords)

### Part 1:

#starting with the point data: SO + myspecies - get a consistent variable label:
##fc_PLSK_WSI_SO has a unique observation ID, and it's always 6-digits. 
##Same label with new numbers is used for the myspecies data:
myspecies_coords$SURVEY_OBSERVATION_ID <- c(1:nrow(myspecies_coords))
myspecies_coords <- rename(myspecies_coords, "GEOMETRY" = "geometry")
#join data according to the unique IDs - first confirm projections then combine:

PLSK_gbif <- st_transform(myspecies_coords, crs=4326)
PLSK_WSI_SO <- st_transform(fc_PLSK_WSI_SO, crs=4326)

PLSK_gbif[setdiff(names(PLSK_WSI_SO), names(PLSK_gbif))] <- NA
PLSK_WSI_SO[setdiff(names(PLSK_gbif), names(PLSK_WSI_SO))] <- NA

PLSK_point_map <- rbind(PLSK_WSI_SO,PLSK_gbif)

#Visualize

ggplot() +
  geom_sf(data = fc_PLSK_range) +
  geom_sf(data = PLSK_point_map) #+
  geom_sf(data = fc_PLSK_EO)
```

```{r}
### Part 2: Intersections:

PLSK_eo_so <- st_intersection(fc_PLSK_EO,fc_PLSK_WSI_SO)
#I note that I'm down to 497 observations, from 1322 SO observations

setdiff(fc_PLSK_EO$SHAPE_ID, PLSK_eo_so$SHAPE_ID)
#there are five polgons that lack any overlap - how best to address?

### We could remove all points within the polygons so that they aren't redundant in the model. 



```

## Generate The Data Citations

```{r Citations}
gbif_cit <- gbif_citation(gbif_data)
gbif_cit
```
